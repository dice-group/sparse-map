#ifndef TSL_SPARSE_MAP_TESTS_SPARSE_ARRAY_HPP_OLD
#define TSL_SPARSE_MAP_TESTS_SPARSE_ARRAY_HPP_OLD

#include <cinttypes>
#include <memory>
#include <numeric>

#include "utility_functions.hpp"
#include "sparse_growth_policy.h"

namespace tsl::detail_sparse_hash {

/**
 * WARNING: the sparse_array class doesn't free the resources allocated through
 * the allocator passed in parameter in each method. You have to manually call
 * `clear(Allocator&)` when you don't need a sparse_array object anymore.
 *
 * The reason is that the sparse_array doesn't store the allocator to avoid
 * wasting space in each sparse_array when the allocator has a size > 0. It only
 * allocates/deallocates objects with the allocator that is passed in parameter.
 *
 *
 *
 * Index denotes a value between [0, BITMAP_NB_BITS), it is an index similar to
 * std::vector. Offset denotes the real position in `m_values` corresponding to
 * an index.
 *
 * We are using raw pointers instead of std::vector to avoid loosing
 * 2*sizeof(size_t) bytes to store the capacity and size of the vector in each
 * sparse_array. We know we can only store up to BITMAP_NB_BITS elements in the
 * array, we don't need such big types.
 *
 *
 * T must be nothrow move constructible and/or copy constructible.
 * Behaviour is undefined if the destructor of T throws an exception.
 *
 * See https://smerity.com/articles/2015/google_sparsehash.html for details on
 * the idea behinds the implementation.
 *
 * TODO Check to use std::realloc and std::memmove when possible
 * TODO: this should just be an struct. There should be an wrapper which knows the allocator and is implemented as a plain type.
 */

    template<typename T, typename Allocator, tsl::sh::sparsity Sparsity>
    class sparse_array {
    public:
        using value_type = T;
        using size_type = std::uint_least8_t;
        using allocator_type = Allocator;
        using allocator_traits = std::allocator_traits<allocator_type>;
        using pointer = typename allocator_traits::pointer;
        using const_pointer = typename allocator_traits::const_pointer;
        using iterator = pointer;
        using const_iterator = const_pointer;

    private:
        static const size_type CAPACITY_GROWTH_STEP =
                (Sparsity == tsl::sh::sparsity::high)
                ? 2
                : (Sparsity == tsl::sh::sparsity::medium)
                  ? 4
                  : 8;  // (Sparsity == tsl::sh::sparsity::low)

        /**
         * Bitmap size configuration.
         * Use 32 bits for the bitmap on 32-bits or less environnement as popcount on
         * 64 bits numbers is slow on these environnement. Use 64 bits bitmap
         * otherwise.
         */
#if SIZE_MAX <= UINT32_MAX
        using bitmap_type = std::uint_least32_t;
        static const std::size_t BITMAP_NB_BITS = 32;
        static const std::size_t BUCKET_SHIFT = 5;
#else
        using bitmap_type = std::uint_least64_t;
        static const std::size_t BITMAP_NB_BITS = 64;
        static const std::size_t BUCKET_SHIFT = 6;
#endif

        static const std::size_t BUCKET_MASK = BITMAP_NB_BITS - 1;

        static_assert(is_power_of_two(BITMAP_NB_BITS),
                      "BITMAP_NB_BITS must be a power of two.");
        static_assert(std::numeric_limits<bitmap_type>::digits >= BITMAP_NB_BITS,
                      "bitmap_type must be able to hold at least BITMAP_NB_BITS.");
        static_assert((std::size_t(1) << BUCKET_SHIFT) == BITMAP_NB_BITS,
                      "(1 << BUCKET_SHIFT) must be equal to BITMAP_NB_BITS.");
        static_assert(std::numeric_limits<size_type>::max() >= BITMAP_NB_BITS,
                      "size_type must be big enough to hold BITMAP_NB_BITS.");
        static_assert(std::is_unsigned<bitmap_type>::value,
                      "bitmap_type must be unsigned.");
        static_assert((std::numeric_limits<bitmap_type>::max() & BUCKET_MASK) ==
                      BITMAP_NB_BITS - 1);

    public:
        /**
         * Map an ibucket [0, bucket_count) in the hash table to a sparse_ibucket
         * (a sparse_array holds multiple buckets, so there is less sparse_array than
         * bucket_count).
         *
         * The bucket ibucket is in
         * m_sparse_buckets[sparse_ibucket(ibucket)][index_in_sparse_bucket(ibucket)]
         * instead of something like m_buckets[ibucket] in a classical hash table.
         */
        static std::size_t sparse_ibucket(std::size_t ibucket) {
            return ibucket >> BUCKET_SHIFT;
        }

        /**
         * Map an ibucket [0, bucket_count) in the hash table to an index in the
         * sparse_array which corresponds to the bucket.
         *
         * The bucket ibucket is in
         * m_sparse_buckets[sparse_ibucket(ibucket)][index_in_sparse_bucket(ibucket)]
         * instead of something like m_buckets[ibucket] in a classical hash table.
         */
        static typename sparse_array::size_type index_in_sparse_bucket(
                std::size_t ibucket) {
            return static_cast<typename sparse_array::size_type>(
                    ibucket & sparse_array::BUCKET_MASK);
        }

        static std::size_t nb_sparse_buckets(std::size_t bucket_count) noexcept {
            if (bucket_count == 0) {
                return 0;
            }

            return std::max<std::size_t>(
                    1, sparse_ibucket(tsl::detail_sparse_hash::round_up_to_power_of_two(
                            bucket_count)));
        }

    public:
        sparse_array() noexcept
                : m_values(nullptr),
                  m_bitmap_vals(0),
                  m_bitmap_deleted_vals(0),
                  m_nb_elements(0),
                  m_capacity(0),
                  m_last_array(false) {}

        //needed for "is_constructible" with no parameters
        sparse_array(std::allocator_arg_t, Allocator const &) noexcept: sparse_array{} {}

        explicit sparse_array(bool last_bucket) noexcept
                : m_values(nullptr),
                  m_bitmap_vals(0),
                  m_bitmap_deleted_vals(0),
                  m_nb_elements(0),
                  m_capacity(0),
                  m_last_array(last_bucket) {}

        //const Allocator needed for MoveInsertable requirement
        sparse_array(size_type capacity, Allocator const &const_alloc)
                : m_values(nullptr),
                  m_bitmap_vals(0),
                  m_bitmap_deleted_vals(0),
                  m_nb_elements(0),
                  m_capacity(capacity),
                  m_last_array(false) {
            if (m_capacity > 0) {
                auto alloc = const_cast<Allocator &>(const_alloc);
                m_values = alloc.allocate(m_capacity);
                tsl_sh_assert(m_values !=
                              nullptr);  // allocate should throw if there is a failure
            }
        }

        //const Allocator needed for MoveInsertable requirement
        sparse_array(const sparse_array &other, Allocator const &const_alloc)
                : m_values(nullptr),
                  m_bitmap_vals(other.m_bitmap_vals),
                  m_bitmap_deleted_vals(other.m_bitmap_deleted_vals),
                  m_nb_elements(0),
                  m_capacity(other.m_capacity),
                  m_last_array(other.m_last_array) {
            tsl_sh_assert(other.m_capacity >= other.m_nb_elements);
            if (m_capacity == 0) {
                return;
            }

            auto alloc = const_cast<Allocator &>(const_alloc);
            m_values = alloc.allocate(m_capacity);
            tsl_sh_assert(m_values !=
                          nullptr);  // allocate should throw if there is a failure
            try {
                for (size_type i = 0; i < other.m_nb_elements; i++) {
                    construct_value(alloc, m_values + i, other.m_values[i]);
                    m_nb_elements++;
                }
            } catch (...) {
                clear(alloc);
                throw;
            }
        }

        sparse_array(sparse_array &&other) noexcept
                : m_values(other.m_values),
                  m_bitmap_vals(other.m_bitmap_vals),
                  m_bitmap_deleted_vals(other.m_bitmap_deleted_vals),
                  m_nb_elements(other.m_nb_elements),
                  m_capacity(other.m_capacity),
                  m_last_array(other.m_last_array) {
            other.m_values = nullptr;
            other.m_bitmap_vals = 0;
            other.m_bitmap_deleted_vals = 0;
            other.m_nb_elements = 0;
            other.m_capacity = 0;
        }

        //const Allocator needed for MoveInsertable requirement
        sparse_array(sparse_array &&other, Allocator const &const_alloc)
                : m_values(nullptr),
                  m_bitmap_vals(other.m_bitmap_vals),
                  m_bitmap_deleted_vals(other.m_bitmap_deleted_vals),
                  m_nb_elements(0),
                  m_capacity(other.m_capacity),
                  m_last_array(other.m_last_array) {
            // TODO: is this only applied if the allocator is different from this' allocator?
            tsl_sh_assert(other.m_capacity >= other.m_nb_elements);
            if (m_capacity == 0) {
                return;
            }

            auto alloc = const_cast<Allocator &>(const_alloc);
            m_values = alloc.allocate(m_capacity);
            tsl_sh_assert(m_values !=
                          nullptr);  // allocate should throw if there is a failure
            try {
                for (size_type i = 0; i < other.m_nb_elements; i++) {
                    construct_value(alloc, m_values + i, std::move(other.m_values[i]));
                    m_nb_elements++;
                }
            } catch (...) {
                clear(alloc);
                throw;
            }
        }

        sparse_array &operator=(const sparse_array &) = delete;

        sparse_array &operator=(sparse_array &&other) noexcept {
            this->m_values = other.m_values;
            this->m_bitmap_vals = other.m_bitmap_vals;
            this->m_bitmap_deleted_vals = other.m_bitmap_deleted_vals;
            this->m_nb_elements = other.m_nb_elements;
            this->m_capacity = other.m_capacity;
            other.m_values = nullptr;
            other.m_bitmap_vals = 0;
            other.m_bitmap_deleted_vals = 0;
            other.m_nb_elements = 0;
            other.m_capacity = 0;
            return *this;
        }


        ~sparse_array() noexcept {
            // The code that manages the sparse_array must have called clear before
            // destruction. See documentation of sparse_array for more details.
            tsl_sh_assert(m_capacity == 0 && m_nb_elements == 0 && m_values == nullptr);
        }

        iterator begin() noexcept { return m_values; }

        iterator end() noexcept { return m_values + m_nb_elements; }

        const_iterator begin() const noexcept { return cbegin(); }

        const_iterator end() const noexcept { return cend(); }

        const_iterator cbegin() const noexcept { return m_values; }

        const_iterator cend() const noexcept { return m_values + m_nb_elements; }

        bool empty() const noexcept { return m_nb_elements == 0; }

        size_type size() const noexcept { return m_nb_elements; }

        void clear(allocator_type &alloc) noexcept {
            destroy_and_deallocate_values(alloc, m_values, m_nb_elements, m_capacity);

            m_values = nullptr;
            m_bitmap_vals = 0;
            m_bitmap_deleted_vals = 0;
            m_nb_elements = 0;
            m_capacity = 0;
        }

        bool last() const noexcept { return m_last_array; }

        void set_as_last() noexcept { m_last_array = true; }

        bool has_value(size_type index) const noexcept {
            tsl_sh_assert(index < BITMAP_NB_BITS);
            return (m_bitmap_vals & (bitmap_type(1) << index)) != 0;
        }

        bool has_deleted_value(size_type index) const noexcept {
            tsl_sh_assert(index < BITMAP_NB_BITS);
            return (m_bitmap_deleted_vals & (bitmap_type(1) << index)) != 0;
        }

        iterator value(size_type index) noexcept {
            tsl_sh_assert(has_value(index));
            return m_values + index_to_offset(index);
        }

        const_iterator value(size_type index) const noexcept {
            tsl_sh_assert(has_value(index));
            return m_values + index_to_offset(index);
        }

        /**
         * Return iterator to set value.
         */
        template<typename... Args>
        iterator set(allocator_type &alloc, size_type index, Args &&... value_args) {
            tsl_sh_assert(!has_value(index));

            const size_type offset = index_to_offset(index);
            insert_at_offset(alloc, offset, std::forward<Args>(value_args)...);

            m_bitmap_vals = (m_bitmap_vals | (bitmap_type(1) << index));
            m_bitmap_deleted_vals =
                    (m_bitmap_deleted_vals & ~(bitmap_type(1) << index));

            m_nb_elements++;

            tsl_sh_assert(has_value(index));
            tsl_sh_assert(!has_deleted_value(index));

            return m_values + offset;
        }

        iterator erase(allocator_type &alloc, iterator position) {
            const size_type offset =
                    static_cast<size_type>(std::distance(begin(), position));
            return erase(alloc, position, offset_to_index(offset));
        }

        // Return the next value or end if no next value
        iterator erase(allocator_type &alloc, iterator position, size_type index) {
            tsl_sh_assert(has_value(index));
            tsl_sh_assert(!has_deleted_value(index));

            const size_type offset =
                    static_cast<size_type>(std::distance(begin(), position));
            erase_at_offset(alloc, offset);

            m_bitmap_vals = (m_bitmap_vals & ~(bitmap_type(1) << index));
            m_bitmap_deleted_vals = (m_bitmap_deleted_vals | (bitmap_type(1) << index));

            m_nb_elements--;

            tsl_sh_assert(!has_value(index));
            tsl_sh_assert(has_deleted_value(index));

            return m_values + offset;
        }

        void swap(sparse_array &other) {
            using std::swap;

            swap(m_values, other.m_values);
            swap(m_bitmap_vals, other.m_bitmap_vals);
            swap(m_bitmap_deleted_vals, other.m_bitmap_deleted_vals);
            swap(m_nb_elements, other.m_nb_elements);
            swap(m_capacity, other.m_capacity);
            swap(m_last_array, other.m_last_array);
        }

        static iterator mutable_iterator(const_iterator pos) {
            return ::tsl::Remove_Const<iterator>::template remove<const_iterator>(pos);
        }

        template<class Serializer>
        void serialize(Serializer &serializer) const {
            const slz_size_type sparse_bucket_size = m_nb_elements;
            serializer(sparse_bucket_size);

            const slz_size_type bitmap_vals = m_bitmap_vals;
            serializer(bitmap_vals);

            const slz_size_type bitmap_deleted_vals = m_bitmap_deleted_vals;
            serializer(bitmap_deleted_vals);

            for (const value_type &value: *this) {
                serializer(value);
            }
        }

        template<class Deserializer>
        static sparse_array deserialize_hash_compatible(Deserializer &deserializer,
                                                        Allocator &alloc) {
            const slz_size_type sparse_bucket_size =
                    deserialize_value<slz_size_type>(deserializer);
            const slz_size_type bitmap_vals =
                    deserialize_value<slz_size_type>(deserializer);
            const slz_size_type bitmap_deleted_vals =
                    deserialize_value<slz_size_type>(deserializer);

            if (sparse_bucket_size > BITMAP_NB_BITS) {
                throw std::runtime_error(
                        "Deserialized sparse_bucket_size is too big for the platform. "
                        "Maximum should be BITMAP_NB_BITS.");
            }

            sparse_array sarray;
            if (sparse_bucket_size == 0) {
                return sarray;
            }

            sarray.m_bitmap_vals = numeric_cast<bitmap_type>(
                    bitmap_vals, "Deserialized bitmap_vals is too big.");
            sarray.m_bitmap_deleted_vals = numeric_cast<bitmap_type>(
                    bitmap_deleted_vals, "Deserialized bitmap_deleted_vals is too big.");

            sarray.m_capacity = numeric_cast<size_type>(
                    sparse_bucket_size, "Deserialized sparse_bucket_size is too big.");
            sarray.m_values = alloc.allocate(sarray.m_capacity);

            try {
                for (size_type ivalue = 0; ivalue < sarray.m_capacity; ivalue++) {
                    construct_value(alloc, sarray.m_values + ivalue,
                                    deserialize_value<value_type>(deserializer));
                    sarray.m_nb_elements++;
                }
            } catch (...) {
                sarray.clear(alloc);
                throw;
            }

            return sarray;
        }

        /**
         * Deserialize the values of the bucket and insert them all in sparse_hash
         * through sparse_hash.insert(...).
         */
        template<class Deserializer, class SparseHash>
        static void deserialize_values_into_sparse_hash(Deserializer &deserializer,
                                                        SparseHash &sparse_hash) {
            const slz_size_type sparse_bucket_size =
                    deserialize_value<slz_size_type>(deserializer);

            const slz_size_type bitmap_vals =
                    deserialize_value<slz_size_type>(deserializer);
            static_cast<void>(bitmap_vals);  // Ignore, not needed

            const slz_size_type bitmap_deleted_vals =
                    deserialize_value<slz_size_type>(deserializer);
            static_cast<void>(bitmap_deleted_vals);  // Ignore, not needed

            for (slz_size_type ivalue = 0; ivalue < sparse_bucket_size; ivalue++) {
                sparse_hash.insert(deserialize_value<value_type>(deserializer));
            }
        }

    private:
        template<typename... Args>
        static void construct_value(allocator_type &alloc, pointer value,
                                    Args &&... value_args) {
            std::allocator_traits<allocator_type>::construct(
                    alloc, detail_sparse_hash::to_address(value), std::forward<Args>(value_args)...);
        }

        static void destroy_value(allocator_type &alloc, pointer value) noexcept {
            std::allocator_traits<allocator_type>::destroy(alloc, detail_sparse_hash::to_address(value));
        }


        static size_type popcount(bitmap_type val) noexcept {
            if (sizeof(bitmap_type) <= sizeof(unsigned int)) {
                return static_cast<size_type>(
                        tsl::detail_popcount::popcount(static_cast<unsigned int>(val)));
            } else {
                return static_cast<size_type>(tsl::detail_popcount::popcountll(val));
            }
        }

        size_type index_to_offset(size_type index) const noexcept {
            tsl_sh_assert(index < BITMAP_NB_BITS);
            return popcount(m_bitmap_vals &
                            ((bitmap_type(1) << index) - bitmap_type(1)));
        }

        // TODO optimize
        size_type offset_to_index(size_type offset) const noexcept {
            tsl_sh_assert(offset < m_nb_elements);

            bitmap_type bitmap_vals = m_bitmap_vals;
            size_type index = 0;
            size_type nb_ones = 0;

            while (bitmap_vals != 0) {
                if ((bitmap_vals & 0x1) == 1) {
                    if (nb_ones == offset) {
                        break;
                    }

                    nb_ones++;
                }

                index++;
                bitmap_vals = bitmap_vals >> 1;
            }

            return index;
        }

        size_type next_capacity() const noexcept {
            return static_cast<size_type>(m_capacity + CAPACITY_GROWTH_STEP);
        }

        /**
         * Insertion
         *
         * Two situations:
         * - Either we are in a situation where
         * std::is_nothrow_move_constructible<value_type>::value is true. In this
         * case, on insertion we just reallocate m_values when we reach its capacity
         * (i.e. m_nb_elements == m_capacity), otherwise we just put the new value at
         * its appropriate place. We can easily keep the strong exception guarantee as
         * moving the values around is safe.
         * - Otherwise we are in a situation where
         * std::is_nothrow_move_constructible<value_type>::value is false. In this
         * case on EACH insertion we allocate a new area of m_nb_elements + 1 where we
         * copy the values of m_values into it and put the new value there. On
         * success, we set m_values to this new area. Even if slower, it's the only
         * way to preserve to strong exception guarantee.
         */
        template<typename... Args, typename U = value_type,
                typename std::enable_if<
                        std::is_nothrow_move_constructible<U>::value>::type * = nullptr>
        void insert_at_offset(allocator_type &alloc, size_type offset,
                              Args &&... value_args) {
            if (m_nb_elements < m_capacity) {
                insert_at_offset_no_realloc(alloc, offset,
                                            std::forward<Args>(value_args)...);
            } else {
                insert_at_offset_realloc(alloc, offset, next_capacity(),
                                         std::forward<Args>(value_args)...);
            }
        }

        template<typename... Args, typename U = value_type,
                typename std::enable_if<!std::is_nothrow_move_constructible<
                        U>::value>::type * = nullptr>
        void insert_at_offset(allocator_type &alloc, size_type offset,
                              Args &&... value_args) {
            insert_at_offset_realloc(alloc, offset, m_nb_elements + 1,
                                     std::forward<Args>(value_args)...);
        }

        template<typename... Args, typename U = value_type,
                typename std::enable_if<
                        std::is_nothrow_move_constructible<U>::value>::type * = nullptr>
        void insert_at_offset_no_realloc(allocator_type &alloc, size_type offset,
                                         Args &&... value_args) {
            tsl_sh_assert(offset <= m_nb_elements);
            tsl_sh_assert(m_nb_elements < m_capacity);

            for (size_type i = m_nb_elements; i > offset; i--) {
                construct_value(alloc, m_values + i, std::move(m_values[i - 1]));
                destroy_value(alloc, m_values + i - 1);
            }

            try {
                construct_value(alloc, m_values + offset,
                                std::forward<Args>(value_args)...);
            } catch (...) {
                for (size_type i = offset; i < m_nb_elements; i++) {
                    construct_value(alloc, m_values + i, std::move(m_values[i + 1]));
                    destroy_value(alloc, m_values + i + 1);
                }
                throw;
            }
        }

        template<typename... Args, typename U = value_type,
                typename std::enable_if<
                        std::is_nothrow_move_constructible<U>::value>::type * = nullptr>
        void insert_at_offset_realloc(allocator_type &alloc, size_type offset,
                                      size_type new_capacity, Args &&... value_args) {
            tsl_sh_assert(new_capacity > m_nb_elements);

            pointer new_values = alloc.allocate(new_capacity);
            // Allocate should throw if there is a failure
            tsl_sh_assert(new_values != nullptr);

            try {
                construct_value(alloc, new_values + offset,
                                std::forward<Args>(value_args)...);
            } catch (...) {
                alloc.deallocate(new_values, new_capacity);
                throw;
            }

            // Should not throw from here
            for (size_type i = 0; i < offset; i++) {
                construct_value(alloc, new_values + i, std::move(m_values[i]));
            }

            for (size_type i = offset; i < m_nb_elements; i++) {
                construct_value(alloc, new_values + i + 1, std::move(m_values[i]));
            }

            destroy_and_deallocate_values(alloc, m_values, m_nb_elements, m_capacity);

            m_values = new_values;
            m_capacity = new_capacity;
        }

        template<typename... Args, typename U = value_type,
                typename std::enable_if<!std::is_nothrow_move_constructible<
                        U>::value>::type * = nullptr>
        void insert_at_offset_realloc(allocator_type &alloc, size_type offset,
                                      size_type new_capacity, Args &&... value_args) {
            tsl_sh_assert(new_capacity > m_nb_elements);

            value_type *new_values = alloc.allocate(new_capacity);
            // Allocate should throw if there is a failure
            tsl_sh_assert(new_values != nullptr);

            size_type nb_new_values = 0;
            try {
                for (size_type i = 0; i < offset; i++) {
                    construct_value(alloc, new_values + i, m_values[i]);
                    nb_new_values++;
                }

                construct_value(alloc, new_values + offset,
                                std::forward<Args>(value_args)...);
                nb_new_values++;

                for (size_type i = offset; i < m_nb_elements; i++) {
                    construct_value(alloc, new_values + i + 1, m_values[i]);
                    nb_new_values++;
                }
            } catch (...) {
                destroy_and_deallocate_values(alloc, new_values, nb_new_values,
                                              new_capacity);
                throw;
            }

            tsl_sh_assert(nb_new_values == m_nb_elements + 1);

            destroy_and_deallocate_values(alloc, m_values, m_nb_elements, m_capacity);

            m_values = new_values;
            m_capacity = new_capacity;
        }

        /**
         * Erasure
         *
         * Two situations:
         * - Either we are in a situation where
         * std::is_nothrow_move_constructible<value_type>::value is true. Simply
         * destroy the value and left-shift move the value on the right of offset.
         * - Otherwise we are in a situation where
         * std::is_nothrow_move_constructible<value_type>::value is false. Copy all
         * the values except the one at offset into a new heap area. On success, we
         * set m_values to this new area. Even if slower, it's the only way to
         * preserve to strong exception guarantee.
         */
        template<typename... Args, typename U = value_type,
                typename std::enable_if<
                        std::is_nothrow_move_constructible<U>::value>::type * = nullptr>
        void erase_at_offset(allocator_type &alloc, size_type offset) noexcept {
            tsl_sh_assert(offset < m_nb_elements);

            destroy_value(alloc, m_values + offset);

            for (size_type i = offset + 1; i < m_nb_elements; i++) {
                construct_value(alloc, m_values + i - 1, std::move(m_values[i]));
                destroy_value(alloc, m_values + i);
            }
        }

        template<typename... Args, typename U = value_type,
                typename std::enable_if<!std::is_nothrow_move_constructible<
                        U>::value>::type * = nullptr>
        void erase_at_offset(allocator_type &alloc, size_type offset) {
            tsl_sh_assert(offset < m_nb_elements);

            // Erasing the last element, don't need to reallocate. We keep the capacity.
            if (offset + 1 == m_nb_elements) {
                destroy_value(alloc, m_values + offset);
                return;
            }

            tsl_sh_assert(m_nb_elements > 1);
            const size_type new_capacity = m_nb_elements - 1;

            value_type *new_values = alloc.allocate(new_capacity);
            // Allocate should throw if there is a failure
            tsl_sh_assert(new_values != nullptr);

            size_type nb_new_values = 0;
            try {
                for (size_type i = 0; i < m_nb_elements; i++) {
                    if (i != offset) {
                        construct_value(alloc, new_values + nb_new_values, m_values[i]);
                        nb_new_values++;
                    }
                }
            } catch (...) {
                destroy_and_deallocate_values(alloc, new_values, nb_new_values,
                                              new_capacity);
                throw;
            }

            tsl_sh_assert(nb_new_values == m_nb_elements - 1);

            destroy_and_deallocate_values(alloc, m_values, m_nb_elements, m_capacity);

            m_values = new_values;
            m_capacity = new_capacity;
        }

    private:
        pointer m_values;

        bitmap_type m_bitmap_vals{};
        bitmap_type m_bitmap_deleted_vals{};

        size_type m_nb_elements{};
        size_type m_capacity{};
        bool m_last_array{};
    };

}
#endif //TSL_SPARSE_MAP_TESTS_SPARSE_ARRAY_HPP_OLD
